= Event driven applications with Serverless Knative Eventing - Introduction
:imagesdir: ../assets/images

++++
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-Y0GQBF9YFH"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-Y0GQBF9YFH');
</script>
<style>
  .nav-container, .pagination, .toolbar {
    display: none !important;
  }
  .doc {    
    max-width: 70rem !important;
  }
</style>
++++

In this module you learn how to leverage AMQ Streams (based on Apache Kafka) and OpenShift Serverless (Knative Eventing) to build an event driven application, without having to deal with the underlying messaging infrastructure.

== Business context

In today's fast-paced digital landscape, businesses collect vast amounts of data through customer interactions, product sales, SEO clicks, and more. However, the true value of this data lies in the ability to drive business intelligence from the data gathered. In this module, you will see how an event-driven architecture can leverage the capabilities of an AI/ML engine to unlock the true potential of data and transform it into valuable business intelligence.

Globex, the fictitious retail company, wants to extend their eCommerce website to allow customers to leave their product reviews. Globex would like to

* Moderate the language comments to ensure foul language is appropriately filtered out
* Build a Sentiment Analysis system to understand the sentiment behind each of the product reviews

== Technical considerations

Globex decides to adopt an Event Driven Architecture using Apache Kafka as the data streaming platform for product reviews and OpenShift Serverless Eventing. The Product Reviews submitted by a customer are pushed to a Kafka topic, which is then consumed by both a Review Moderation Service (moderate for foul/abusive language) and Sentiment Analysis Service (scores the sentiment as positive or negative).

The data flows in and out of different systems through the OpenShift Serverless Eventing architecture which uses brokers, sources and triggers to build a scalable, fully decoupled system.

Once a review is moderated and marked as suitable, this is persisted in the Globex Product Review DB (PostgreSql) to be then shown on the Products page. As a first step, the Sentiment Analysis score can be viewed in the Kafka messages and at a later time will be used to build a Dashboard (Grafana) to view how well a particular category of products is performing over different time periods.

image::serverless/serverless-story.png[width=80%]

Here is an overview of some of the critical components which are brought together to build this system.


=== Red Hat streams for Apache Kafka

streams for Apache Kafka will be your core event stream platform where the review comments are stored and propagated to other systems and services to moderate and analyse them.


=== Red Hat OpenShift Serverless

Red Hat OpenShift Serverless, built on Knative, makes it easy to build serverless and event-driven appslications on Kubernetes. It has two main components:

* *Serving* supports autoscaling, including scaling pods down to zero. 
* *Eventing* enables event-driven architecture which can route events from event producers (known as sources) to event consumers (known as sinks) that receive events. These events conform to the https://cloudevents.io/[Cloud Events^] specification.

TIP: Cloud Events makes it easy for the services and systems to interact with each other in a standard way. 

== A graphical representation of the architecture:

image::serverless/serverless-architecture-diagram.png[]

The architecture uses Kafka for messaging, Knative for event driven architecture, and AI based Knative Services for processing the reviews.

. User submits a review via the Globex product page.
. The Reviews Service API receives the review, and 
  emits a CloudEvent to the Event Sink via HTTP POST.
. The KafkaSink persists this incoming CloudEvent to a suitable Apache Kafka Topic.
. The Knative KafkaSource captures messages from Kafka and sends them as CloudEvents to the Knative Event Broker.
. The Knative KafkaSource reads the messages stored in Kafka topics, and sends them as CloudEvents through HTTP to the Knative Broker for Apache Kafka.
. The configured Triggers filter receives all the events from the Broker, and  based on their type routes them to the appropriate Knative Services.
. The two AI based Knative Services send Cloud Events to the Kakfa Sink with details of review rating and moderation results. The third service persists the review in the databased
. The moderated reviews are fetched and displayed on the product page.

== Implementation

In the next chapter, you will be guided through the implementation and deployment of this solution. Since this solution involves way more than what can be achieved during a workshop, a number of components are already in place. And you will focus on a few key activities which will give you a good understanding of building an event-driven application.

Proceed to the xref:./module-serverless-instructions.adoc[instructions] for this module.
